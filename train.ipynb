{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrYl6Fgv2cVJ",
        "outputId": "4d6508a8-7596-4f18-8a64-460fe558fd78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install poutyne"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gz-z1XehCSBA",
        "outputId": "757e9d02-89b2-4700-d517-c21bbb7741d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: poutyne in /usr/local/lib/python3.10/dist-packages (1.16)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from poutyne) (1.22.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from poutyne) (2.0.0+cu118)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (from poutyne) (0.11.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->poutyne) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->poutyne) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->poutyne) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->poutyne) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->poutyne) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->poutyne) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->poutyne) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->poutyne) (16.0.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torchmetrics->poutyne) (23.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->poutyne) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->poutyne) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kj18iND43mv8",
        "outputId": "0e11e7dc-9a50-4725-c06f-b83dd6b51677"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (0.4.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pymagnitude-light in /usr/local/lib/python3.10/dist-packages (0.1.147)\n",
            "Requirement already satisfied: fasteners>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from pymagnitude-light) (0.18)\n",
            "Requirement already satisfied: lz4>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pymagnitude-light) (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from pymagnitude-light) (1.22.4)\n",
            "Requirement already satisfied: xxhash>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from pymagnitude-light) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "# %pip install --upgrade git+https://github.com/GRAAL-Research/poutyne.git@dev #install poutyne\n",
        "%pip install --upgrade colorama #install colorama\n",
        "%pip install --upgrade pymagnitude-light #install pymagnitude-light\n",
        "%matplotlib inline\n",
        "\n",
        "import gzip\n",
        "import os\n",
        "import pickle\n",
        "import shutil\n",
        "import warnings\n",
        "\n",
        "import requests\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from poutyne import set_seeds\n",
        "from poutyne.framework import Experiment\n",
        "from pymagnitudelight import Magnitude\n",
        "from torch.nn.functional import cross_entropy\n",
        "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence, pad_sequence\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MpZYjlu_Km1A"
      },
      "outputs": [],
      "source": [
        "dimension = 300\n",
        "num_layer = 1\n",
        "bidirectional = False\n",
        "\n",
        "lstm_network = nn.LSTM(\n",
        "    input_size=dimension,\n",
        "    hidden_size=dimension,\n",
        "    num_layers=num_layer,\n",
        "    bidirectional=bidirectional,\n",
        "    batch_first=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bq61Y7L4KpT6"
      },
      "outputs": [],
      "source": [
        "input_dim = dimension  # the output of the LSTM\n",
        "tag_dimension = 10\n",
        "\n",
        "fully_connected_network = nn.Linear(input_dim, tag_dimension)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xk6JRbhbOIpP",
        "outputId": "d2d4b3ce-6266-4f18-aab8-3f94b4883e36"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ],
      "source": [
        "input_dim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCiX2nmvKrN1"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\")\n",
        "\n",
        "batch_size = 64\n",
        "lr = 0.1\n",
        "\n",
        "epoch_number = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FrXMNXm4Ks3X"
      },
      "outputs": [],
      "source": [
        "set_seeds(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dS6-O6z6JH_m"
      },
      "outputs": [],
      "source": [
        "train_data = pickle.load(open(\"/content/labeled_data (1).p\", \"rb\"))  # 728,789 examples\n",
        "valid_data = pickle.load(open(\"/content/labeled_data_valid (1).p\", \"rb\"))  # 182,198 examples\n",
        "test_data = pickle.load(open(\"/content/labeled_data_valid (1).p\", \"rb\"))  # 100,000 examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7Aby_Z22qrL"
      },
      "outputs": [],
      "source": [
        "def download_from_url(model: str, saving_dir: str, extension: str):\n",
        "    \"\"\"\n",
        "    Simple function to download the content of a file from a distant repository.\n",
        "    \"\"\"\n",
        "    print(\"Downloading the model.\")\n",
        "    model_url = \"https://graal.ift.ulaval.ca/public/deepparse/{}.\" + extension\n",
        "    url = model_url.format(model)\n",
        "    r = requests.get(url)\n",
        "\n",
        "    os.makedirs(saving_dir, exist_ok=True)\n",
        "    open(os.path.join(saving_dir, f\"{model}.{extension}\"), \"wb\").write(r.content)\n",
        "\n",
        "\n",
        "def download_fasttext_magnitude_embeddings(saving_dir):\n",
        "    \"\"\"\n",
        "    Function to download the magnitude pre-trained fastText model.\n",
        "    \"\"\"\n",
        "    model = \"fasttext\"\n",
        "    extension = \"magnitude\"\n",
        "    file_name = os.path.join(saving_dir, f\"{model}.{extension}\")\n",
        "    if not os.path.isfile(file_name):\n",
        "        warnings.warn(\n",
        "            \"The fastText pre-trained word embeddings will be download in magnitude format (2.3 GO), \"\n",
        "            \"this process will take several minutes.\"\n",
        "        )\n",
        "        extension = extension + \".gz\"\n",
        "        download_from_url(model=model, saving_dir=saving_dir, extension=extension)\n",
        "        gz_file_name = file_name + \".gz\"\n",
        "        print(\"Unzip the model.\")\n",
        "        with gzip.open(os.path.join(saving_dir, gz_file_name), \"rb\") as f:\n",
        "            with open(os.path.join(saving_dir, file_name), \"wb\") as f_out:\n",
        "                shutil.copyfileobj(f, f_out)\n",
        "        os.remove(os.path.join(saving_dir, gz_file_name))\n",
        "    return file_name\n",
        "\n",
        "\n",
        "class EmbeddingVectorizer:\n",
        "    def __init__(self, path=\"./\"):\n",
        "        \"\"\"\n",
        "        Embedding vectorizer\n",
        "        \"\"\"\n",
        "        file_name = download_fasttext_magnitude_embeddings(saving_dir=path)\n",
        "        self.embedding_model = Magnitude(file_name)\n",
        "    def __call__(self, addresses):\n",
        "        \"\"\"\n",
        "        Vectorizes a list of addresses.\n",
        "        \"\"\"\n",
        "        vectorized_addresses = []\n",
        "        for address in addresses:\n",
        "            embeddings = []\n",
        "            for word in address.split():\n",
        "                embeddings.append(self.embedding_model.query(word))\n",
        "            vectorized_addresses.append(embeddings)\n",
        "        return vectorized_addresses\n",
        "\n",
        "    def __call__(self, address):\n",
        "        \"\"\"\n",
        "        Convert address to embedding vectors\n",
        "        :param address: The address to convert\n",
        "        :return: The embeddings vectors\n",
        "        \"\"\"\n",
        "        embeddings = []\n",
        "        for word in address.split():\n",
        "            embeddings.append(self.embedding_model.query(word))\n",
        "        return embeddings\n",
        "\n",
        "\n",
        "embedding_vectorizer = EmbeddingVectorizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJPOvnsM3Xpi"
      },
      "outputs": [],
      "source": [
        "class DatasetBucket:\n",
        "    def __init__(self, data, embedding_vectorizer):\n",
        "        self.data = data\n",
        "        self.embedding_vectorizer = embedding_vectorizer\n",
        "        self.tags_set = {\n",
        "    'flat_apartment_number' : 0,\n",
        "    'society_name' : 1,\n",
        "    # 'building no': 2,\n",
        "    'street': 2,\n",
        "    'landmark': 3,\n",
        "    'sub_locality' : 4,\n",
        "    'area_locality_name' : 5,\n",
        "    'city_town': 6,\n",
        "    'pincode': 7,\n",
        "    'unknown': 8\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, item):  # We vectorize when data is asked\n",
        "        data = self.data[item]\n",
        "        return self._item_vectorizing(data)\n",
        "\n",
        "    def _item_vectorizing(self, item):\n",
        "        address = item[0]\n",
        "        address_vector = self.embedding_vectorizer(address)\n",
        "\n",
        "        tags = item[1]\n",
        "        idx_tags = self._convert_tags_to_idx(tags)\n",
        "\n",
        "        return address_vector, idx_tags\n",
        "\n",
        "    def _convert_tags_to_idx(self, tags):\n",
        "        idx_tags = []\n",
        "        for tag in tags:\n",
        "            idx_tags.append(self.tags_set[tag])\n",
        "        return idx_tags\n",
        "\n",
        "\n",
        "train_dataset_vectorizer = DatasetBucket(train_data, embedding_vectorizer)\n",
        "valid_dataset_vectorizer = DatasetBucket(valid_data, embedding_vectorizer)\n",
        "test_dataset_vectorizer = DatasetBucket(test_data, embedding_vectorizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qyCwNbhJ04m",
        "outputId": "009af467-69a9-46fb-80e2-9645ac81c483"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The vectorized address is now a list of vectors [array([ 0.02325456,  0.03707229,  0.0049116 ,  0.03062604,  0.08376793,\n",
            "        0.00642177,  0.00135967,  0.0208587 ,  0.02357467, -0.29028088,\n",
            "       -0.02337095, -0.02262662,  0.0039097 , -0.00678048, -0.06434749,\n",
            "       -0.01164662,  0.02810531, -0.05848467, -0.04093806,  0.04993952,\n",
            "        0.0456836 ,  0.07107708,  0.0392685 ,  0.02746471,  0.01665277,\n",
            "        0.00869989,  0.04787574, -0.02994883, -0.01290582,  0.02296908,\n",
            "        0.00421662, -0.01034104, -0.00485097, -0.03158264, -0.05035931,\n",
            "        0.05072984, -0.01351666,  0.00195226,  0.02320314, -0.00362392,\n",
            "        0.01605988, -0.02856024,  0.00963255,  0.04986977, -0.01333941,\n",
            "        0.14832153,  0.01825037, -0.00837681, -0.02942097, -0.00389294,\n",
            "        0.01853295,  0.04559087, -0.05780271, -0.04407778,  0.02088004,\n",
            "       -0.06555015,  0.07033247, -0.02001717,  0.01117153, -0.00516496,\n",
            "        0.02736741,  0.00383148,  0.00583375,  0.03039943,  0.0100781 ,\n",
            "        0.11103168, -0.02155904, -0.02796025,  0.03372316,  0.02022707,\n",
            "       -0.12855945, -0.04209812, -0.04075969, -0.016163  , -0.04802766,\n",
            "        0.0527572 , -0.02018104,  0.05946489, -0.03828527, -0.02297753,\n",
            "        0.09009581,  0.05518781,  0.03693113, -0.21915823,  0.04262452,\n",
            "       -0.0768476 , -0.06808432,  0.00695199,  0.02434058, -0.00845073,\n",
            "        0.01431179,  0.10821079,  0.00610286,  0.05399229,  0.03898216,\n",
            "       -0.01277867, -0.10048805, -0.02092194, -0.02707804,  0.07741603,\n",
            "       -0.02479805,  0.0360135 ,  0.05899419,  0.00182219,  0.04320462,\n",
            "        0.0436289 ,  0.00289657,  0.02069611, -0.02436367,  0.06666115,\n",
            "        0.00480923, -0.03565225,  0.02115668,  0.04076143, -0.08322801,\n",
            "        0.03813741, -0.0016584 ,  0.00941866, -0.01786302,  0.11422825,\n",
            "       -0.00115697,  0.04086944,  0.04772625, -0.04105341,  0.05636974,\n",
            "       -0.04330992, -0.00632222, -0.04775066,  0.04182496, -0.04160137,\n",
            "       -0.12039154, -0.10038211, -0.06107235, -0.05173306, -0.04363044,\n",
            "        0.04308277, -0.24447031, -0.01953357,  0.01340823,  0.02868244,\n",
            "        0.05847341, -0.03195226, -0.03762487, -0.04362816,  0.0151933 ,\n",
            "       -0.08052558, -0.04120952, -0.02581768,  0.10137649,  0.02034733,\n",
            "       -0.09593191, -0.09689799, -0.03927334,  0.00488278,  0.00436113,\n",
            "        0.04279753,  0.02471076, -0.03268827,  0.03598284, -0.00333275,\n",
            "       -0.05014042, -0.00669046,  0.01377359, -0.05573769, -0.04124854,\n",
            "       -0.01448991, -0.03086299,  0.02151087, -0.01152509,  0.00892858,\n",
            "       -0.06146968,  0.0049795 , -0.04562649,  0.09635156,  0.0322337 ,\n",
            "        0.07148995, -0.08322607,  0.01698581, -0.03261189, -0.11229739,\n",
            "       -0.04853008,  0.03163227,  0.13090252, -0.01561136, -0.04788398,\n",
            "       -0.12473165,  0.03222118,  0.10716925, -0.00141125, -0.02835431,\n",
            "       -0.13961767,  0.0525562 ,  0.01873351, -0.05998707, -0.01286711,\n",
            "        0.00452125, -0.0995443 , -0.02028358, -0.01393608,  0.05075765,\n",
            "       -0.02128259, -0.05420062,  0.02556401,  0.07752059,  0.07382256,\n",
            "        0.02588922, -0.006173  ,  0.06797488,  0.04112994,  0.04371973,\n",
            "        0.03922825,  0.04625104, -0.01736551, -0.0066936 ,  0.01952533,\n",
            "       -0.04221725,  0.03313681, -0.0184474 , -0.09900477,  0.03816008,\n",
            "        0.01124505,  0.06596707, -0.05848102,  0.05812382, -0.04232167,\n",
            "        0.05160958,  0.02435937,  0.03036763, -0.06746535, -0.06007791,\n",
            "        0.049735  , -0.05426204, -0.05294302,  0.06621067, -0.01720412,\n",
            "       -0.04700151, -0.00539374, -0.05648866,  0.0299223 , -0.01052673,\n",
            "        0.05403459, -0.02327687,  0.06453163, -0.04018435, -0.07544859,\n",
            "       -0.01605016,  0.04225599,  0.03293873, -0.03146931, -0.02666126,\n",
            "        0.04926553,  0.04250659,  0.06560975,  0.00178149,  0.07825146,\n",
            "        0.10758529, -0.06233697,  0.0341711 ,  0.06903883,  0.06155516,\n",
            "        0.03865335,  0.01145894, -0.1971727 , -0.04897505,  0.01890338,\n",
            "        0.03511267,  0.00398459, -0.04404252,  0.04679864, -0.04698163,\n",
            "        0.04710958, -0.03972532,  0.01862202, -0.027326  ,  0.00932772,\n",
            "       -0.02421499, -0.02581251, -0.03164915, -0.06450692,  0.01608448,\n",
            "        0.11221439,  0.08167399, -0.00508319, -0.00183617, -0.00160636,\n",
            "        0.03453179,  0.15744308, -0.0822762 , -0.03366461, -0.06304488,\n",
            "       -0.09741047,  0.04915635, -0.0022057 , -0.01212   ,  0.00529189,\n",
            "        0.09220138,  0.02105258, -0.15829801, -0.08536008,  0.03470719]), array([ 0.0336284 ,  0.00368465,  0.11213475, -0.00788954,  0.0324092 ,\n",
            "       -0.04147343, -0.0577904 ,  0.06317096, -0.06661532,  0.0523015 ,\n",
            "       -0.02245121,  0.01842685, -0.02893843, -0.06817704, -0.09942014,\n",
            "       -0.01301043,  0.00824364, -0.02462396,  0.01846228, -0.01296564,\n",
            "        0.01119553,  0.03978158,  0.0077321 ,  0.0152969 ,  0.05552566,\n",
            "        0.09361902,  0.00676846,  0.04840282, -0.01130096,  0.0487307 ,\n",
            "        0.09907626, -0.0577617 ,  0.0231115 , -0.01328382, -0.00821515,\n",
            "        0.08675434, -0.01849554, -0.10168891,  0.09620643,  0.02565334,\n",
            "       -0.00031335,  0.08476225, -0.00150038,  0.06634372,  0.07910837,\n",
            "        0.02373208,  0.0193721 , -0.04404446,  0.10690199, -0.04271944,\n",
            "       -0.03897039,  0.03363634,  0.03610007,  0.02173287,  0.02936766,\n",
            "        0.00589598,  0.05826424, -0.0420244 ,  0.00759452, -0.03493373,\n",
            "       -0.09925674, -0.00593446,  0.00979035, -0.02174881, -0.03139262,\n",
            "       -0.05581868, -0.00506607,  0.01073331, -0.03651959, -0.02832885,\n",
            "       -0.09400543,  0.047564  , -0.06287293, -0.0543184 , -0.03493367,\n",
            "       -0.0335957 , -0.06663138,  0.06512405, -0.03910409, -0.00309971,\n",
            "        0.03452783, -0.03957135,  0.06128631, -0.12950546,  0.01834421,\n",
            "       -0.07273884, -0.03613991, -0.06408728,  0.10506287, -0.03724837,\n",
            "       -0.05374066, -0.1144108 ,  0.05197448,  0.01720811,  0.00955941,\n",
            "        0.02055309,  0.04493111, -0.02029144,  0.10959009,  0.0590372 ,\n",
            "       -0.00217461,  0.03039972,  0.04183849, -0.04449303,  0.01382226,\n",
            "        0.00779974,  0.04923919, -0.09287357, -0.05515186,  0.01805614,\n",
            "        0.03965744,  0.08411866, -0.0298915 ,  0.01191729, -0.0171162 ,\n",
            "       -0.00038389, -0.02895753,  0.06344976,  0.02001501,  0.09455078,\n",
            "        0.08563519,  0.04160602, -0.02876795, -0.04000794,  0.00373141,\n",
            "       -0.03153764, -0.06703103, -0.05727229, -0.03371354, -0.05667722,\n",
            "       -0.02813924,  0.13283776, -0.05560703,  0.02252866,  0.12739318,\n",
            "        0.00145266, -0.2489262 ,  0.01612162, -0.06428722, -0.00794683,\n",
            "       -0.03967871, -0.02766344, -0.04636268,  0.02898074,  0.06966635,\n",
            "        0.04463504, -0.02670534,  0.07638591, -0.05181253,  0.01851318,\n",
            "        0.07828558,  0.07429955,  0.01036226, -0.09843725,  0.07558596,\n",
            "        0.02491667,  0.04041558, -0.11784052, -0.02896741,  0.02535898,\n",
            "        0.00867877, -0.00906985,  0.00229613, -0.07911144, -0.02568862,\n",
            "       -0.0211425 ,  0.01283631, -0.13708058,  0.11716229,  0.02469545,\n",
            "        0.05797817, -0.04294634,  0.03430831,  0.00406753,  0.03682424,\n",
            "        0.02360388, -0.07488515, -0.05808218,  0.04346077,  0.00175549,\n",
            "        0.04219358, -0.0414466 ,  0.09489334,  0.0269484 ,  0.01798718,\n",
            "       -0.07424658, -0.00865007,  0.1726505 , -0.02943758,  0.0511603 ,\n",
            "        0.00804338,  0.07549311, -0.06512892,  0.01391451,  0.02301548,\n",
            "       -0.11408245,  0.07790762, -0.03874457,  0.07324387, -0.0164706 ,\n",
            "        0.04543352,  0.07295774, -0.00312214, -0.01042556,  0.04053272,\n",
            "       -0.11109251,  0.13274579, -0.07542908,  0.01281908, -0.00961735,\n",
            "        0.07125224,  0.00688892, -0.02066159, -0.08500945, -0.06035829,\n",
            "       -0.08488347,  0.01749321,  0.13902974, -0.03098951, -0.04990852,\n",
            "       -0.00203221, -0.00872214, -0.00887232,  0.0209652 ,  0.02212414,\n",
            "       -0.03027927, -0.04550829, -0.03337063,  0.07887993, -0.01997655,\n",
            "        0.13158901,  0.00194763,  0.07172618, -0.12502419,  0.05434265,\n",
            "       -0.00571314, -0.04462082, -0.03482101, -0.00412388,  0.00194367,\n",
            "       -0.10330318, -0.02729693,  0.10188538, -0.11520535,  0.01505328,\n",
            "       -0.0858349 ,  0.02398278,  0.01251993, -0.04248101,  0.05445942,\n",
            "        0.05058979,  0.00457497, -0.02670419,  0.06494217, -0.05119246,\n",
            "        0.03531634,  0.01931067,  0.08258921, -0.03963127,  0.01675864,\n",
            "        0.01441728,  0.02381354,  0.01448762,  0.08421633, -0.00252274,\n",
            "        0.08549926,  0.0608186 , -0.03983466, -0.06387565, -0.02833082,\n",
            "        0.02767249,  0.09767287,  0.05644842,  0.01434912,  0.00720237,\n",
            "        0.01288814, -0.02349476,  0.00896014,  0.09079907,  0.00213948,\n",
            "       -0.03880325, -0.02415593,  0.04884638,  0.03069485,  0.01645531,\n",
            "       -0.02485982, -0.01868113, -0.1105673 , -0.01477743,  0.06169835,\n",
            "        0.1603155 ,  0.01405408,  0.02984044,  0.0225229 , -0.04996437,\n",
            "       -0.04940565, -0.03962818, -0.03412929,  0.04117315, -0.01107621]), array([ 6.587300e-02, -6.831920e-02,  6.917570e-02,  1.033594e-01,\n",
            "        4.486980e-02,  1.588940e-02,  7.857840e-02,  3.070450e-02,\n",
            "        5.719520e-02, -6.916410e-02, -8.402900e-02,  1.319530e-02,\n",
            "       -1.638260e-02, -9.489840e-02,  1.278849e-01, -6.572200e-02,\n",
            "        6.365760e-02, -6.873800e-03, -1.080336e-01,  2.238210e-02,\n",
            "        4.296470e-02, -2.934400e-02, -8.560590e-02, -1.185960e-02,\n",
            "       -3.569180e-02,  3.153330e-02, -6.955940e-02,  8.840710e-02,\n",
            "        5.781630e-02,  9.000460e-02,  1.387250e-02, -1.745410e-02,\n",
            "       -4.371400e-02, -1.395030e-02,  4.966310e-02,  1.165190e-02,\n",
            "       -5.189990e-02,  2.300820e-02, -5.438030e-02,  5.001440e-02,\n",
            "       -5.343920e-02,  5.481800e-02, -1.837090e-02,  3.913950e-02,\n",
            "        2.129730e-02,  4.083900e-03, -6.804820e-02, -3.642180e-02,\n",
            "        3.272340e-02, -1.347640e-02, -1.902870e-02,  7.550510e-02,\n",
            "        1.879260e-02,  4.068640e-02, -3.017690e-02,  6.164600e-02,\n",
            "        3.899000e-04, -1.350574e-01, -5.006370e-02,  1.570550e-02,\n",
            "        1.037930e-02,  3.574920e-02, -7.089760e-02, -7.306680e-02,\n",
            "       -3.360200e-03, -4.085860e-02,  1.293401e-01,  2.428500e-03,\n",
            "       -2.181350e-02, -3.854900e-03,  2.193110e-02,  1.195340e-02,\n",
            "        8.387840e-02, -3.842100e-03,  2.868300e-02, -4.039940e-02,\n",
            "        6.940620e-02,  4.995590e-02, -2.405900e-03, -3.331100e-02,\n",
            "        2.638820e-02, -7.538720e-02, -8.104410e-02, -1.491187e-01,\n",
            "        7.525740e-02, -5.451230e-02, -4.973400e-03, -8.359220e-02,\n",
            "       -1.520480e-02, -7.060820e-02,  7.999490e-02,  4.264530e-02,\n",
            "        2.227540e-02,  1.988940e-02, -2.897420e-02,  8.861470e-02,\n",
            "        5.346400e-02, -8.821240e-02, -9.408700e-02,  9.775700e-03,\n",
            "       -1.547180e-02,  1.317290e-02, -5.684690e-02, -8.587810e-02,\n",
            "       -4.466300e-03, -3.361170e-02,  1.149571e-01,  3.048910e-02,\n",
            "        3.195000e-03, -3.632590e-02,  4.533690e-02,  2.098650e-02,\n",
            "       -2.365300e-03, -4.615810e-02,  1.570320e-02, -5.671600e-02,\n",
            "       -7.793210e-02,  8.644040e-02,  8.039480e-02, -7.152150e-02,\n",
            "        6.374900e-03, -4.510790e-02, -2.875920e-02, -5.432300e-02,\n",
            "        5.924050e-02, -3.050180e-02, -2.849300e-02, -6.937760e-02,\n",
            "        7.215950e-02, -4.592610e-02, -5.497250e-02,  9.999170e-02,\n",
            "       -1.202320e-02, -5.287300e-02,  6.589960e-02, -6.396750e-02,\n",
            "       -1.104871e-01, -7.312060e-02, -3.441350e-02,  4.111060e-02,\n",
            "       -6.151600e-02,  2.376220e-02, -1.170662e-01, -8.510170e-02,\n",
            "        2.187020e-02, -7.119510e-02,  4.264910e-02,  1.093206e-01,\n",
            "       -6.105560e-02,  3.665290e-02,  1.052100e-01, -3.693900e-03,\n",
            "        2.077280e-02, -9.949880e-02,  3.002080e-02, -5.961640e-02,\n",
            "       -7.687180e-02, -1.516524e-01, -4.268230e-02,  4.779510e-02,\n",
            "        3.665380e-02, -3.769990e-02, -4.302500e-03,  4.271820e-02,\n",
            "       -1.237997e-01, -1.868660e-02, -2.750840e-02, -6.896710e-02,\n",
            "        4.014680e-02, -3.265050e-02,  2.536240e-02,  2.554320e-02,\n",
            "       -1.285482e-01,  1.430880e-02,  6.565100e-03,  6.465450e-02,\n",
            "       -1.688990e-02, -1.702716e-01,  2.718440e-02, -6.129370e-02,\n",
            "       -1.187590e-02, -6.154690e-02, -2.731410e-02, -2.210100e-03,\n",
            "       -4.246480e-02,  8.927380e-02,  2.478510e-02, -3.019880e-02,\n",
            "        2.414320e-02,  1.208729e-01, -1.842960e-02,  3.425410e-02,\n",
            "       -2.859250e-02,  1.659500e-02, -2.238810e-02, -3.274690e-02,\n",
            "       -5.068300e-03,  1.420510e-02, -5.175120e-02,  1.539650e-02,\n",
            "       -9.016500e-03,  1.795870e-02, -2.574690e-02,  2.307940e-02,\n",
            "        6.287930e-02, -8.561510e-02,  2.104310e-01, -9.285900e-03,\n",
            "       -1.406760e-02,  3.157600e-03,  4.900170e-02, -2.998920e-02,\n",
            "       -4.725000e-03, -2.556400e-03,  4.562600e-03,  7.228980e-02,\n",
            "       -6.433330e-02,  5.849060e-02,  7.878700e-02, -3.607150e-02,\n",
            "       -7.304000e-03,  8.250130e-02, -5.044010e-02,  5.974100e-02,\n",
            "       -1.788800e-03,  8.996770e-02, -2.664870e-02,  4.618530e-02,\n",
            "       -7.743890e-02,  6.919020e-02,  4.194190e-02, -1.570460e-02,\n",
            "        1.178700e-02,  3.526420e-02,  6.352900e-03,  7.759810e-02,\n",
            "        1.812000e-02,  1.089000e-04, -5.338330e-02, -1.343000e-03,\n",
            "       -1.388260e-02, -8.271300e-03,  6.937240e-02, -4.328570e-02,\n",
            "        3.423600e-02, -4.701770e-02,  2.919320e-02, -5.617090e-02,\n",
            "        3.182850e-02, -5.061430e-02,  2.314400e-03,  1.194010e-02,\n",
            "        4.144170e-02,  3.019600e-02,  4.655130e-02, -1.467417e-01,\n",
            "        4.735330e-02,  1.287720e-02,  8.680730e-02, -5.667200e-02,\n",
            "       -7.770320e-02, -5.783260e-02,  4.967970e-02,  2.175590e-02,\n",
            "       -6.645600e-03, -1.971770e-02,  4.584680e-02, -8.494450e-02,\n",
            "       -1.936040e-02, -1.086203e-01,  1.113128e-01, -4.711900e-03,\n",
            "       -1.024360e-01,  5.306210e-02, -3.131840e-02, -5.651090e-02,\n",
            "        2.474120e-02, -9.136140e-02, -3.831810e-02,  7.131000e-02,\n",
            "       -4.553530e-02, -5.210410e-02, -4.740380e-02,  5.087120e-02,\n",
            "       -3.226790e-02, -1.589660e-02,  4.831000e-03,  3.406030e-02,\n",
            "        5.231400e-03, -6.309370e-02,  1.588340e-02,  4.117260e-02,\n",
            "        6.236560e-02, -5.292470e-02, -2.108660e-02,  5.382920e-02,\n",
            "        1.201180e-02, -4.275570e-02,  1.875870e-02,  7.642450e-02],\n",
            "      dtype=float32), array([-1.02811033e-02, -5.46287494e-02,  2.38158490e-02,  4.15355525e-02,\n",
            "        3.24692864e-03,  5.25093083e-03, -1.52044699e-02,  4.60459161e-02,\n",
            "       -3.00480226e-02,  1.07566123e-01, -7.25780620e-02, -1.10232226e-02,\n",
            "        5.79434629e-02, -1.03756324e-01,  1.26840056e-02,  8.86992835e-02,\n",
            "        3.37789237e-02,  8.08665932e-02, -2.07074365e-03,  6.46726569e-02,\n",
            "       -1.83784654e-03,  3.85862082e-04,  2.10646010e-02, -2.29675465e-02,\n",
            "       -1.41841718e-02,  2.59017384e-02,  6.12192514e-02,  4.49459836e-02,\n",
            "        2.00235482e-02,  4.30265972e-02,  7.69382279e-03, -1.22467063e-02,\n",
            "       -2.20753384e-02, -4.61484496e-02, -6.94174728e-03,  7.51330633e-02,\n",
            "       -4.05506805e-02, -5.80705339e-02, -1.79083646e-02, -5.24843722e-02,\n",
            "        2.86912409e-02,  1.28143783e-01, -7.00252252e-02, -3.24881754e-03,\n",
            "        6.85352591e-02,  1.18876624e-01,  1.30609782e-02,  5.03916355e-02,\n",
            "        2.57103833e-02, -1.11543933e-02, -5.96484160e-02, -3.94847328e-02,\n",
            "       -4.93133043e-02,  1.17609789e-01, -3.08789339e-02, -5.16504901e-02,\n",
            "        3.70156352e-02, -8.95833198e-02, -1.10733440e-02,  5.42297020e-02,\n",
            "       -6.52274920e-02, -1.94575274e-02,  3.04860214e-02,  5.02384408e-03,\n",
            "        2.54740251e-02, -1.92993999e-02,  5.53969563e-02,  9.66680672e-03,\n",
            "        6.42628487e-03, -1.42308632e-02, -1.46353789e-01, -1.60434100e-02,\n",
            "       -2.26321705e-02, -6.15069842e-03, -5.65392218e-02, -1.45687601e-05,\n",
            "        1.36820175e-02,  4.30781976e-02,  4.84567715e-02,  1.67355118e-02,\n",
            "        2.72705039e-02, -1.74002586e-02,  5.13993738e-02, -1.41205667e-01,\n",
            "       -3.96462956e-02, -1.05473713e-01,  5.77985439e-03, -2.75641482e-02,\n",
            "        9.02978503e-02, -4.19361317e-02, -7.73832764e-03, -6.10247879e-02,\n",
            "       -1.13779873e-02,  2.52837024e-02,  8.43917779e-02, -1.50400770e-02,\n",
            "       -3.89632957e-02, -3.62351393e-03, -3.84924537e-03,  3.45420484e-02,\n",
            "        9.98793554e-03,  1.03083712e-02,  4.16045338e-02, -5.79373811e-03,\n",
            "       -4.23409845e-02,  3.90115316e-03,  1.35482538e-02, -1.64283119e-02,\n",
            "       -1.43332435e-02, -3.89753946e-02,  5.73536206e-03, -5.03252185e-02,\n",
            "        4.10384535e-02, -1.27206713e-02, -4.87272083e-02, -4.58098155e-02,\n",
            "        4.85563637e-02, -1.36162579e-02,  1.70029655e-03, -6.05363653e-02,\n",
            "        5.25354982e-02, -9.39200348e-02, -2.26849086e-02,  1.81772227e-02,\n",
            "        8.91550247e-02,  1.65329213e-01,  6.10714452e-02, -3.00820002e-02,\n",
            "       -1.71281274e-02,  3.52418722e-03, -1.21864175e-02,  5.96203088e-02,\n",
            "       -4.09109208e-02,  1.86529029e-02, -2.90760756e-02, -3.77668568e-02,\n",
            "       -3.13682393e-01, -1.06571404e-01, -1.53769642e-02, -8.55284186e-02,\n",
            "       -6.89191476e-02, -9.22774566e-03, -8.79233503e-02,  9.49420422e-02,\n",
            "        9.22694033e-02, -1.32643713e-02, -3.04225671e-02, -3.41863765e-02,\n",
            "        6.43744359e-03, -3.74022066e-02,  4.09523073e-02, -2.42677821e-02,\n",
            "       -3.14885823e-02,  1.10987144e-01, -2.12225681e-02,  8.39747665e-02,\n",
            "        2.98381183e-02, -3.88799317e-02,  1.18035189e-02, -3.70102071e-02,\n",
            "       -4.78652456e-02,  4.81230175e-02, -2.49548604e-02, -3.25476237e-03,\n",
            "       -2.19932549e-02, -1.26461299e-02,  3.54952843e-03,  4.19155282e-03,\n",
            "       -7.52102427e-03,  1.02744394e-01, -3.88539962e-02, -2.64460926e-02,\n",
            "        9.27972143e-03, -4.41733300e-02,  1.69297321e-02, -2.16287042e-02,\n",
            "        9.60417968e-03,  2.83857566e-02, -1.39547159e-02,  1.91592934e-02,\n",
            "        8.89243820e-02, -1.12547801e-01, -1.06251757e-02,  3.69729462e-02,\n",
            "       -2.71358743e-02, -1.83800328e-02, -5.24938830e-02,  3.18485162e-01,\n",
            "        5.40969537e-02,  4.55493196e-02, -2.72028479e-02, -1.37667321e-02,\n",
            "       -4.28415641e-02, -4.22419727e-02,  2.29806072e-02, -3.94651860e-02,\n",
            "       -3.10471715e-02, -6.41686780e-03, -1.09095227e-02, -3.96411835e-02,\n",
            "        3.04403434e-02,  9.34330287e-02, -1.38879843e-02, -3.24864489e-02,\n",
            "        1.31337349e-03,  5.28419337e-03,  7.45885440e-02,  7.71562809e-02,\n",
            "        5.01867142e-02, -1.78716226e-02, -2.85103433e-02,  2.18049844e-02,\n",
            "       -5.01810128e-03, -4.05290677e-02,  1.12370784e-01, -3.71901295e-02,\n",
            "       -3.90881206e-02,  4.55934461e-02,  6.84618677e-02, -1.17396690e-01,\n",
            "        3.87272252e-02,  7.42908218e-02, -2.84938347e-02,  1.19109100e-01,\n",
            "        5.81978585e-02, -1.15298098e-02, -1.46657721e-02,  2.84352579e-02,\n",
            "        6.23667382e-02,  2.06105191e-02, -7.01893343e-02,  4.00055262e-02,\n",
            "       -7.36875667e-02, -6.08577642e-02,  5.43035273e-02, -2.63662526e-02,\n",
            "        2.96828586e-02,  7.96339837e-02, -7.91847150e-03, -2.16129307e-02,\n",
            "       -9.13876903e-02, -2.10594720e-02,  2.35347532e-02,  3.66634375e-02,\n",
            "       -2.72060013e-02, -4.07388775e-02,  2.64020978e-02,  7.14496392e-02,\n",
            "       -6.79961449e-02,  2.72907069e-02,  4.38282730e-03,  7.77572256e-02,\n",
            "       -9.30307216e-02,  7.39548557e-02, -3.22699461e-03,  1.32174864e-02,\n",
            "       -3.23765261e-02,  3.43722225e-02, -7.81729848e-02, -8.54002542e-03,\n",
            "        1.07728402e-02, -6.56433086e-02, -4.06256839e-02, -3.72392340e-02,\n",
            "        5.98590922e-03,  3.27080047e-02,  3.61994700e-02, -2.16410226e-02,\n",
            "       -7.68808144e-02, -1.23641227e-01,  7.04006445e-03, -9.02001955e-03,\n",
            "        1.60529547e-02,  8.34230372e-02, -3.22424294e-02, -2.78472539e-02,\n",
            "       -1.40433366e-02,  4.41171837e-03,  5.60441909e-02,  4.85516287e-02,\n",
            "        6.17865841e-02, -2.76222588e-02, -2.14240925e-02,  6.56034649e-02,\n",
            "        7.14007716e-02,  9.93195296e-02, -2.11798220e-02, -1.45721348e-01,\n",
            "       -7.49301843e-03, -7.88680266e-03,  1.13751684e-01,  1.71171801e-02,\n",
            "        2.12199522e-02,  9.47721356e-02, -1.92581815e-02, -7.80586106e-02,\n",
            "        8.61063821e-02, -2.75054919e-02,  8.29199162e-03, -2.23936248e-02]), array([ 3.05926796e-02, -5.82528049e-02, -4.83467969e-02, -3.11318386e-02,\n",
            "       -2.32575669e-02, -2.99527656e-02,  3.92042133e-02, -2.70029820e-02,\n",
            "       -6.19272966e-02,  6.04960924e-02, -1.14438878e-01,  7.64447396e-04,\n",
            "        7.26732938e-02,  5.36110286e-03, -8.22991263e-02,  4.10142317e-02,\n",
            "       -6.87051438e-03, -5.74973584e-03,  5.07476724e-02,  7.60375789e-02,\n",
            "        9.68073208e-02, -1.04909820e-02,  6.80395684e-02,  1.57584196e-02,\n",
            "        1.98166904e-02, -2.52929963e-02, -9.91606757e-02, -2.39207081e-02,\n",
            "       -6.97463701e-02, -4.41292211e-02,  4.36540583e-02, -2.42456391e-02,\n",
            "        7.12640881e-03, -2.13474466e-02, -4.82042298e-02,  6.98534777e-02,\n",
            "       -4.38698594e-02, -6.86798055e-02, -7.17480966e-02,  2.77342273e-02,\n",
            "       -9.09525224e-02,  4.71223403e-02,  8.15070269e-02,  4.66308146e-02,\n",
            "        1.19621760e-01, -7.34649667e-02, -1.38194239e-02,  2.70988416e-02,\n",
            "        1.21317050e-01, -4.72417288e-03,  9.72460552e-02, -2.01155599e-02,\n",
            "       -4.43531203e-02,  2.28184349e-02,  5.01982616e-03,  5.37952526e-03,\n",
            "        1.95119777e-02,  2.45550890e-02, -9.27611776e-02,  2.53749850e-02,\n",
            "       -1.90121036e-02, -5.47039442e-02,  8.61954844e-02,  1.45441465e-02,\n",
            "       -6.03085615e-02, -7.98773159e-02,  1.40374423e-01, -8.62516947e-02,\n",
            "       -8.41825245e-02, -9.11830844e-02, -3.78839130e-02, -6.17845558e-02,\n",
            "        3.12622605e-02,  9.27314245e-02, -3.99461948e-02,  4.30455276e-02,\n",
            "        3.62558235e-03,  2.24978762e-02,  4.06511476e-02,  8.73416272e-02,\n",
            "       -2.61653860e-02, -6.89486614e-02,  7.41844375e-03, -1.40745741e-01,\n",
            "        5.81365211e-02,  2.82211314e-02,  1.55744942e-03,  1.64949831e-02,\n",
            "       -8.22177956e-03,  4.26063226e-02,  1.13928975e-02, -3.09692132e-02,\n",
            "        2.03382679e-02,  7.63577099e-02, -2.20273594e-02,  8.80313209e-03,\n",
            "       -5.53054621e-02,  4.75855056e-02, -4.12473352e-03,  3.30728725e-03,\n",
            "       -5.50670777e-02, -1.01423272e-01,  1.08660449e-03,  1.03178312e-01,\n",
            "       -4.37656072e-02,  4.22310502e-02, -3.60064034e-02,  2.76939432e-02,\n",
            "       -3.89395665e-03, -2.56239159e-03, -3.60319876e-02, -3.80693468e-02,\n",
            "       -4.06439810e-02, -3.10090115e-02, -1.28882790e-01, -6.11015178e-02,\n",
            "       -1.13310732e-02,  6.77084506e-03,  4.23833528e-02, -1.10311477e-02,\n",
            "       -1.85394194e-02, -2.72797563e-02, -2.47744498e-03, -4.06358968e-02,\n",
            "        7.14907820e-04,  6.62393565e-02, -1.58689143e-01, -9.21185279e-03,\n",
            "       -8.88525757e-02, -9.07822525e-02, -5.84380303e-02,  9.52789163e-02,\n",
            "       -7.93387273e-03,  8.59049916e-03,  4.92021983e-02,  2.40751204e-02,\n",
            "       -3.61823555e-01,  3.05527406e-02, -6.43067206e-03, -1.26510099e-01,\n",
            "        2.75605156e-02,  9.64349315e-02, -8.83106673e-02,  2.47526634e-02,\n",
            "       -6.75997763e-03, -8.18063452e-02, -2.08543487e-02,  7.36882577e-02,\n",
            "        6.79298080e-03,  2.92695468e-02,  3.76725385e-02,  1.03516998e-02,\n",
            "        1.38947817e-02,  4.98902767e-02, -5.74221824e-02,  6.19322583e-02,\n",
            "        1.41983269e-02, -2.69958182e-02, -7.75913128e-02, -2.23158035e-02,\n",
            "        2.70761769e-02,  2.92951008e-02,  8.27939051e-02, -5.73842134e-02,\n",
            "       -1.87220933e-02, -5.01960894e-03,  1.80745041e-03, -2.95389591e-02,\n",
            "       -2.34350709e-02,  2.39172558e-02,  3.20176440e-02,  5.02383644e-02,\n",
            "       -1.00905125e-01,  4.41838679e-02, -6.60927740e-02, -2.25581113e-02,\n",
            "       -1.16395910e-01, -4.55442224e-04,  1.13055731e-01,  2.15616200e-02,\n",
            "        9.49844899e-02, -3.02549981e-03, -5.43339290e-02,  6.40354597e-04,\n",
            "       -4.89756017e-02, -1.33659250e-02, -5.08879862e-02,  4.07586461e-02,\n",
            "        2.67266149e-04,  7.54214758e-02, -9.58732318e-03, -1.99318117e-02,\n",
            "        1.08314136e-02, -9.51862302e-04, -3.02371998e-04, -7.53404896e-02,\n",
            "        8.69233876e-02,  4.60074328e-02, -8.40379966e-02, -5.13904236e-02,\n",
            "       -3.84116478e-02,  4.86620399e-02, -3.55858282e-02,  4.82999754e-02,\n",
            "       -6.71853562e-04, -2.10440311e-02, -4.27614311e-02,  5.35463397e-02,\n",
            "       -4.39270333e-02, -2.08947356e-03, -2.30603804e-02,  4.19447856e-02,\n",
            "       -1.83045262e-02,  1.84354762e-02,  3.67027585e-02,  1.62284241e-02,\n",
            "        3.09335539e-02, -5.20134979e-02,  7.22757998e-03, -6.28495808e-02,\n",
            "        5.74675661e-02,  4.68444750e-02, -5.35832256e-02,  1.81963487e-02,\n",
            "       -2.12032687e-02,  5.05601187e-02,  2.18474924e-02,  4.53073777e-04,\n",
            "        4.37766393e-02,  4.81218422e-02,  3.53746477e-02,  5.13402530e-02,\n",
            "       -4.16422339e-02,  2.40140176e-02, -5.76432429e-02,  5.39233290e-02,\n",
            "        8.72409900e-03, -3.29210453e-02,  9.20629707e-03,  2.18079292e-02,\n",
            "       -3.20038564e-02, -1.31475366e-02,  1.01438695e-02, -1.55346421e-02,\n",
            "       -3.58666478e-02, -3.32162100e-02,  2.99642568e-02,  7.02932988e-02,\n",
            "       -4.62120673e-03,  2.26056035e-02, -7.45790268e-02, -2.30930950e-02,\n",
            "       -6.30635715e-02,  8.39384464e-02, -5.87490285e-03, -1.43725220e-02,\n",
            "        6.26552271e-02, -1.65412756e-02,  5.39607621e-02, -4.23894213e-02,\n",
            "        8.49484946e-02,  2.76526028e-02, -1.26857942e-01, -6.93297173e-02,\n",
            "       -2.31770789e-02,  9.59001426e-02, -3.21085577e-02, -1.59302996e-02,\n",
            "       -1.20794513e-02, -8.38083923e-02,  4.16455524e-02,  7.34433736e-02,\n",
            "        6.25193311e-02,  1.94213395e-02, -1.08166353e-01,  3.04876660e-02,\n",
            "        9.79314025e-02, -3.88917432e-02,  6.46438764e-02, -2.87404752e-02,\n",
            "        1.21018388e-01,  8.14305924e-04, -2.06869230e-02,  5.39980882e-02,\n",
            "       -1.68024027e-02,  4.76123063e-02, -3.19000316e-02,  6.72579964e-02,\n",
            "       -1.60493807e-02, -3.13528280e-02,  6.64173399e-02,  1.19353560e-01,\n",
            "        7.60839826e-02, -3.93248034e-02,  1.73358844e-02,  1.27969420e-02,\n",
            "        3.51156240e-03, -7.64251613e-02, -5.97826384e-02,  1.84215075e-02]), array([ 1.867400e-03, -9.025960e-02, -6.529690e-02, -2.168110e-02,\n",
            "       -1.851160e-02,  2.608050e-02,  3.811150e-02,  3.309520e-02,\n",
            "        5.368900e-02, -2.969430e-02, -5.653760e-02,  3.268120e-02,\n",
            "       -3.042900e-03,  1.448258e-01,  5.139600e-03, -6.814390e-02,\n",
            "       -8.920830e-02,  5.289870e-02, -5.783010e-02,  9.080100e-03,\n",
            "        2.861830e-02,  3.683200e-03,  3.074140e-02, -2.354840e-02,\n",
            "       -1.538370e-02, -1.366370e-02, -3.927160e-02, -7.449710e-02,\n",
            "       -1.906150e-02, -4.518630e-02,  5.357030e-02, -1.480430e-02,\n",
            "        1.107923e-01, -6.332170e-02, -7.067060e-02,  1.490520e-02,\n",
            "       -7.391390e-02, -1.063760e-02, -6.126540e-02, -1.559630e-02,\n",
            "        4.466490e-02,  7.061380e-02, -5.094900e-02, -4.036380e-02,\n",
            "        5.801350e-02, -1.380520e-02,  3.420970e-02,  5.732700e-03,\n",
            "        4.853830e-02, -5.523190e-02, -2.195210e-02, -2.450190e-02,\n",
            "       -1.093010e-01, -5.320320e-02,  2.087270e-02,  4.448750e-02,\n",
            "       -7.088800e-03, -1.645300e-02, -5.270970e-02,  5.795000e-03,\n",
            "       -1.159006e-01,  1.545640e-02, -1.175105e-01, -3.443990e-02,\n",
            "        5.217600e-03, -6.801320e-02,  4.883760e-02, -9.765640e-02,\n",
            "        8.153950e-02, -2.656790e-02, -2.207380e-02, -3.835200e-03,\n",
            "        4.634640e-02, -2.774130e-02,  9.827330e-02, -8.669240e-02,\n",
            "        6.797200e-03,  7.163460e-02, -5.081980e-02, -6.886160e-02,\n",
            "       -3.271000e-03, -1.624370e-02, -1.023869e-01, -2.458160e-02,\n",
            "       -3.068090e-02,  5.119100e-03,  4.978290e-02,  1.460350e-02,\n",
            "       -5.581000e-03,  6.569220e-02, -3.898350e-02,  7.045390e-02,\n",
            "        1.152568e-01,  5.687110e-02,  2.571110e-02,  1.012990e-02,\n",
            "        5.676100e-03, -1.128459e-01,  8.223780e-02,  2.054540e-02,\n",
            "        3.820380e-02, -8.670720e-02,  3.241250e-02, -1.120931e-01,\n",
            "        3.229280e-02,  8.621600e-03,  3.323490e-02, -1.651870e-02,\n",
            "       -1.490710e-02,  1.529520e-02, -2.593920e-02,  2.130300e-02,\n",
            "       -3.072190e-02, -4.257800e-03, -3.201160e-02, -2.085080e-02,\n",
            "        9.173800e-02, -4.041070e-02, -6.131470e-02,  1.157670e-02,\n",
            "       -1.068184e-01,  1.158115e-01,  5.595690e-02, -6.539180e-02,\n",
            "       -8.754940e-02,  3.038860e-02, -4.020680e-02,  3.648000e-04,\n",
            "        5.779340e-02, -1.982960e-02,  3.500380e-02,  1.094229e-01,\n",
            "        4.516630e-02, -1.960240e-02,  7.240810e-02, -9.372830e-02,\n",
            "       -1.965408e-01, -1.388000e-04,  2.107740e-02, -7.692370e-02,\n",
            "        2.021030e-02,  1.518270e-02,  3.912240e-02, -6.604410e-02,\n",
            "        1.735280e-02,  9.606680e-02,  5.060650e-02, -9.509350e-02,\n",
            "        3.261860e-02, -2.876240e-02,  7.502460e-02,  1.336526e-01,\n",
            "        5.213250e-02,  4.801310e-02,  4.320300e-03,  6.483350e-02,\n",
            "       -6.799770e-02, -7.342860e-02,  2.575180e-02, -3.404780e-02,\n",
            "       -4.990000e-02, -5.137660e-02, -3.529860e-02,  1.192780e-02,\n",
            "       -8.450290e-02, -1.270130e-02, -3.243200e-03, -3.986130e-02,\n",
            "       -1.554600e-02,  6.810560e-02,  5.935640e-02,  6.367720e-02,\n",
            "        4.828220e-02, -1.944850e-02,  4.132400e-02, -1.065830e-02,\n",
            "       -4.782330e-02, -6.393860e-02,  1.089759e-01,  2.636360e-02,\n",
            "        1.442264e-01,  4.344600e-02, -4.054770e-02,  3.659110e-02,\n",
            "       -3.853540e-02, -9.612800e-02, -7.929620e-02, -4.194360e-02,\n",
            "        3.750870e-02, -1.295367e-01, -4.619980e-02, -2.575710e-02,\n",
            "       -5.364970e-02,  2.200950e-02, -1.291799e-01,  6.261590e-02,\n",
            "        2.300990e-02,  6.007260e-02, -1.324000e-04,  1.599510e-02,\n",
            "        3.713660e-02, -6.798890e-02, -5.522260e-02, -1.221200e-03,\n",
            "        1.164898e-01,  6.700130e-02,  4.286510e-02,  8.892000e-03,\n",
            "        1.624570e-02, -2.312010e-02,  5.360060e-02, -3.132120e-02,\n",
            "       -7.435770e-02, -1.473600e-02, -3.605330e-02,  5.987240e-02,\n",
            "        5.213100e-03,  8.723380e-02, -2.629380e-02,  1.891240e-02,\n",
            "        7.362450e-02, -7.141730e-02,  1.485400e-03, -1.555140e-02,\n",
            "       -2.461070e-02, -1.211369e-01, -3.242500e-03,  3.876280e-02,\n",
            "        8.296180e-02,  6.296900e-03,  5.225770e-02,  1.496790e-02,\n",
            "        9.182090e-02,  5.448650e-02, -1.305254e-01, -1.971040e-02,\n",
            "       -2.406030e-02,  1.963020e-02,  1.022981e-01,  4.288580e-02,\n",
            "        3.154090e-02, -3.962150e-02,  2.443290e-02, -2.008790e-02,\n",
            "       -4.997240e-02, -1.067623e-01,  6.082350e-02, -1.598640e-02,\n",
            "       -3.018420e-02,  2.977810e-02, -5.873530e-02,  4.166470e-02,\n",
            "        1.466040e-02,  1.733180e-02,  5.620940e-02,  1.787140e-02,\n",
            "        2.198470e-02, -3.608290e-02,  1.065683e-01,  1.014357e-01,\n",
            "        3.883930e-02,  2.868150e-02,  1.147250e-02, -8.606300e-02,\n",
            "        1.077130e-02,  1.488420e-02,  5.349020e-02, -1.947920e-02,\n",
            "        1.040220e-02, -2.166760e-02,  8.918880e-02, -1.065373e-01,\n",
            "        1.564930e-02,  3.504240e-02,  4.434010e-02, -1.178657e-01,\n",
            "        2.170690e-02,  2.037540e-02,  4.220720e-02,  7.651300e-02,\n",
            "       -8.571940e-02, -1.952440e-02,  1.395830e-02,  1.283680e-02,\n",
            "        5.899170e-02,  8.235440e-02, -1.573040e-02, -9.291720e-02,\n",
            "        3.533020e-02, -5.818030e-02, -6.580940e-02, -3.873410e-02,\n",
            "        9.654250e-02, -7.833750e-02,  3.658700e-02, -1.012860e-01,\n",
            "        4.223150e-02, -4.230000e-04,  2.210870e-02,  5.320200e-03],\n",
            "      dtype=float32), array([ 6.268460e-02, -1.142883e-01,  1.946110e-02,  6.385620e-02,\n",
            "        5.133910e-02, -3.196200e-02,  4.899580e-02,  6.445800e-03,\n",
            "        5.096110e-02, -8.210300e-02,  5.287900e-03,  2.940570e-02,\n",
            "        4.601980e-02, -9.840810e-02,  1.468208e-01, -1.015630e-02,\n",
            "        2.679580e-02, -5.093270e-02,  6.612600e-03,  1.815570e-02,\n",
            "        2.967860e-02,  5.643030e-02,  1.140530e-02,  5.807870e-02,\n",
            "       -3.599640e-02, -4.420120e-02, -5.162520e-02, -2.376240e-02,\n",
            "        5.878810e-02,  2.168200e-02,  8.544180e-02,  3.297170e-02,\n",
            "       -1.164350e-02, -8.327980e-02, -4.242670e-02,  4.627400e-03,\n",
            "       -4.559040e-02,  4.940470e-02, -6.668600e-03,  5.290080e-02,\n",
            "       -2.469620e-02,  7.065040e-02, -2.899930e-02,  6.510000e-03,\n",
            "        1.703280e-01,  1.559730e-02, -2.277240e-02,  3.989300e-03,\n",
            "        1.417390e-02,  2.177390e-02, -6.034700e-03,  1.061736e-01,\n",
            "       -7.247020e-02,  7.602480e-02,  3.184790e-02, -5.069840e-02,\n",
            "        9.812050e-02, -6.462690e-02, -2.959200e-02,  2.524750e-02,\n",
            "        7.355700e-03,  6.133640e-02, -6.034560e-02,  8.188400e-03,\n",
            "        7.674820e-02, -5.101220e-02, -1.308380e-02, -1.247760e-02,\n",
            "        4.437340e-02,  1.302910e-02, -4.268270e-02, -3.653270e-02,\n",
            "       -8.594630e-02, -6.753200e-02,  9.029800e-03,  1.481630e-02,\n",
            "       -6.200800e-03,  1.210683e-01, -4.670170e-02, -1.754280e-02,\n",
            "        5.760010e-02, -2.959480e-02, -4.492820e-02, -1.414910e-01,\n",
            "        7.620820e-02,  2.113930e-02,  2.817700e-02, -6.602850e-02,\n",
            "        2.085080e-02, -6.817110e-02,  1.536346e-01,  4.220810e-02,\n",
            "        2.368900e-03, -1.189270e-02, -8.362510e-02,  4.757700e-03,\n",
            "        2.792580e-02, -3.848610e-02,  6.188980e-02,  8.578160e-02,\n",
            "        1.124320e-02, -1.346380e-02, -8.791790e-02, -1.006852e-01,\n",
            "        9.992290e-02, -5.245910e-02,  3.788980e-02,  6.217890e-02,\n",
            "       -6.153590e-02, -5.841520e-02, -3.793200e-03,  4.004460e-02,\n",
            "        9.220700e-03, -8.721800e-03,  6.064900e-02, -2.402120e-02,\n",
            "       -9.746470e-02, -9.506360e-02,  1.059071e-01, -1.592670e-02,\n",
            "       -9.468800e-03, -6.499920e-02, -6.837960e-02,  1.449780e-02,\n",
            "        4.784520e-02,  4.436400e-03, -9.544160e-02,  5.235910e-02,\n",
            "       -3.740620e-02,  1.597500e-02, -5.360790e-02,  1.129190e-01,\n",
            "       -4.249550e-02,  2.742100e-03,  4.458800e-02, -2.782580e-02,\n",
            "       -8.465120e-02, -1.148820e-02,  6.166130e-02, -5.081300e-03,\n",
            "       -4.407300e-03, -3.227360e-02, -1.652450e-02, -1.146462e-01,\n",
            "        1.686311e-01,  2.152570e-02, -5.532830e-02,  1.782310e-02,\n",
            "       -5.982980e-02,  6.586430e-02,  5.900820e-02,  3.699840e-02,\n",
            "       -5.609800e-03, -9.280550e-02,  5.002130e-02, -2.048200e-03,\n",
            "        5.725900e-03, -8.259390e-02, -9.286960e-02,  9.698000e-04,\n",
            "       -1.773870e-02, -1.109076e-01, -2.102100e-03,  4.194000e-03,\n",
            "       -1.105750e-01,  5.043020e-02,  2.373960e-02, -4.851160e-02,\n",
            "        1.483000e-02, -5.445640e-02,  1.254994e-01, -2.274350e-02,\n",
            "        8.178700e-02, -2.142950e-02,  2.481340e-02,  3.588190e-02,\n",
            "        9.373660e-02, -9.801630e-02, -2.561520e-02,  1.917900e-02,\n",
            "       -6.875400e-03, -3.976690e-02,  7.509100e-02,  7.842770e-02,\n",
            "        4.557380e-02,  8.459480e-02,  3.549030e-02,  1.507320e-02,\n",
            "        4.661700e-03,  3.369280e-02,  3.708160e-02,  5.924440e-02,\n",
            "       -2.943000e-02,  4.026440e-02, -7.745230e-02, -5.956710e-02,\n",
            "       -1.254292e-01, -4.445100e-03,  5.576680e-02,  1.968580e-02,\n",
            "       -1.331500e-02, -7.782640e-02, -1.202110e-02,  2.229180e-02,\n",
            "       -6.144060e-02, -2.738150e-02,  1.344432e-01,  8.888060e-02,\n",
            "        3.454680e-02, -7.185570e-02,  8.484090e-02, -1.034840e-02,\n",
            "        1.000671e-01, -7.192190e-02, -3.659750e-02,  2.212880e-02,\n",
            "       -4.291430e-02,  1.161000e-01, -3.341930e-02, -5.929790e-02,\n",
            "       -2.733060e-02,  3.258700e-02, -2.455810e-02,  8.868800e-03,\n",
            "       -1.911900e-02, -3.214750e-02,  5.579770e-02, -2.033570e-02,\n",
            "       -1.296370e-01,  1.029321e-01, -1.364080e-02,  5.158400e-02,\n",
            "       -7.897640e-02,  1.553400e-02, -1.617900e-02,  1.930240e-02,\n",
            "        1.737300e-02, -2.084700e-03, -2.623740e-02, -1.762950e-02,\n",
            "        1.500860e-02, -1.442660e-02,  4.861150e-02, -2.237497e-01,\n",
            "        7.083300e-03, -2.280000e-05,  3.351190e-02, -5.908340e-02,\n",
            "        5.365880e-02, -6.432390e-02, -1.612590e-02,  3.691440e-02,\n",
            "        6.583390e-02,  5.101510e-02,  4.438570e-02, -2.415850e-02,\n",
            "        3.571030e-02,  9.448600e-03, -1.505000e-03, -6.210310e-02,\n",
            "       -3.227920e-02,  3.412310e-02,  5.955680e-02, -2.368210e-02,\n",
            "        5.300400e-02, -1.961700e-02,  2.026260e-02,  1.786710e-02,\n",
            "        9.517530e-02, -3.598070e-02,  1.205738e-01,  7.086370e-02,\n",
            "       -8.152140e-02,  1.420430e-02, -2.719160e-02, -3.537580e-02,\n",
            "       -3.790440e-02, -5.870000e-02, -2.793110e-02,  6.892950e-02,\n",
            "       -2.709680e-02, -2.415660e-02, -9.305720e-02,  4.754000e-04,\n",
            "        1.013160e-02, -3.861380e-02, -3.431410e-02, -2.482740e-02,\n",
            "       -8.838500e-03, -1.529510e-02, -2.315400e-03,  4.889110e-02,\n",
            "        4.311390e-02, -4.037860e-02,  4.707750e-02,  2.790320e-02,\n",
            "       -1.189900e-02, -4.548200e-02, -2.490100e-02,  5.529770e-02],\n",
            "      dtype=float32), array([-4.13605411e-03, -5.62116360e-03,  5.09339644e-02, -1.35348400e-02,\n",
            "        5.61234930e-02,  5.38337506e-02,  1.58428019e-02,  3.77750742e-02,\n",
            "       -3.03088669e-02, -2.64738989e-01,  1.30344201e-02, -2.35706967e-02,\n",
            "       -4.02512264e-02, -2.57938290e-02, -5.33125300e-02,  2.74577970e-02,\n",
            "        1.64824577e-02, -3.52564462e-02, -4.45318808e-02, -2.04267602e-02,\n",
            "       -1.74032111e-02,  2.38613803e-03,  3.68407801e-02, -3.57249461e-02,\n",
            "       -1.70894088e-02, -2.88585449e-02, -3.34104491e-02,  2.89272332e-02,\n",
            "        7.71184734e-02,  4.17158073e-03, -1.63573748e-02,  2.94951932e-03,\n",
            "        1.04818459e-02,  6.08815603e-03, -9.90348338e-02,  1.97338232e-02,\n",
            "       -1.26177981e-01,  1.53169437e-04, -3.64380276e-02, -1.58920522e-02,\n",
            "       -3.59881920e-02,  3.74660136e-02, -5.85678795e-02,  4.09238130e-02,\n",
            "        6.95483190e-03,  1.59586911e-01,  4.24749836e-02, -2.59001731e-02,\n",
            "       -1.97339998e-04, -3.47408025e-02,  4.18657715e-02,  3.16301036e-02,\n",
            "       -3.82563501e-02,  1.85361613e-02,  2.28801207e-02, -8.59750018e-02,\n",
            "        4.24737458e-02, -6.36060382e-02,  5.83577538e-02, -2.50610982e-02,\n",
            "       -3.32192489e-02,  2.25697498e-02,  9.55194253e-03, -5.62409280e-02,\n",
            "       -6.63586745e-03,  6.96444603e-02,  4.72859532e-02,  7.64048314e-02,\n",
            "        8.81025266e-03,  2.57411543e-02, -4.78731515e-02, -7.08558115e-02,\n",
            "        2.49117332e-02,  1.82045070e-02,  5.62783102e-02,  5.47636998e-02,\n",
            "       -7.63754764e-02,  8.26791950e-02,  7.18811083e-02, -2.75002598e-02,\n",
            "       -2.88446204e-03, -2.62853000e-02,  8.20144841e-02, -2.15459849e-01,\n",
            "       -5.56500944e-03, -2.33778749e-02, -1.81305159e-02, -1.03246385e-01,\n",
            "       -1.90728787e-02,  4.48378135e-02, -1.75384121e-02, -5.89787198e-02,\n",
            "       -2.02818970e-02,  1.66713931e-02, -6.92269413e-04,  7.34881319e-02,\n",
            "        5.52067884e-03,  4.63165581e-02,  3.67904280e-02,  4.11062494e-02,\n",
            "       -5.48922469e-02, -1.91628389e-02, -1.05318930e-02,  3.61937756e-02,\n",
            "       -1.79134439e-02,  5.55977487e-02, -6.90535657e-02,  4.34888029e-03,\n",
            "       -7.38258193e-03, -3.68542240e-02,  1.49035992e-02, -4.50984554e-03,\n",
            "        3.70590505e-02,  6.06566372e-02, -6.29135342e-02, -1.12378181e-03,\n",
            "       -1.15722929e-01,  2.62933239e-02, -2.13928810e-02,  8.09911591e-02,\n",
            "        7.56248692e-02, -1.30264131e-02,  2.13992385e-02,  4.24337792e-03,\n",
            "        1.31300880e-02, -1.73436246e-02, -9.36418505e-03, -8.96894431e-03,\n",
            "       -1.67270908e-02, -7.53454519e-02, -4.96190801e-02, -1.65690473e-01,\n",
            "       -2.90651785e-02, -2.36866369e-02,  2.01129772e-02,  3.07180292e-02,\n",
            "       -3.45533339e-01,  7.34932978e-02, -7.46320928e-03,  1.35121552e-02,\n",
            "        2.58882063e-03, -5.29219827e-02, -1.28638552e-02, -4.95264164e-02,\n",
            "        5.60586016e-04, -2.36602409e-02, -3.07821796e-02, -2.22223328e-02,\n",
            "        1.46981573e-02,  1.92861745e-03,  6.55165448e-03, -3.02453911e-02,\n",
            "        1.90650781e-03,  6.81136947e-03, -3.83654475e-02, -3.43957728e-02,\n",
            "        1.30759520e-02, -4.07108247e-02,  2.43488128e-02, -9.70308509e-02,\n",
            "        4.03217949e-02,  2.85462229e-02,  2.52554804e-02,  1.89587257e-02,\n",
            "        2.73534642e-02, -2.90213714e-02, -9.54414357e-02, -4.27930633e-03,\n",
            "        1.38203078e-03,  4.10483082e-02, -3.64566402e-02,  3.60237888e-02,\n",
            "       -6.63511768e-02,  6.47714213e-03, -6.62320686e-03,  1.22076397e-02,\n",
            "        3.03846112e-02,  2.53645940e-02,  4.65633270e-03, -3.07936369e-02,\n",
            "       -7.06653152e-02, -3.44570715e-02,  5.77804258e-02, -4.15281504e-02,\n",
            "        1.08177825e-02, -5.94771244e-02,  4.38904986e-02,  1.03431381e-01,\n",
            "        8.90570576e-02,  2.03932692e-03, -1.54149620e-01,  3.35725380e-02,\n",
            "       -7.89295344e-02, -2.30509085e-02, -2.52215462e-02, -1.68914969e-02,\n",
            "        5.13651373e-03, -5.77561185e-03, -1.40586541e-02, -2.87265377e-03,\n",
            "        2.07391911e-02, -1.01077225e-01,  4.14103506e-02,  4.41051453e-02,\n",
            "       -1.69158948e-02,  6.06808785e-02, -2.75139194e-02,  1.62887267e-02,\n",
            "        7.93237539e-03,  4.31089752e-02,  6.99665031e-02,  6.08375518e-02,\n",
            "       -1.64728680e-02, -3.85508858e-02, -2.58751524e-02, -8.32046881e-02,\n",
            "       -4.10576972e-02, -6.67560680e-03,  7.22843556e-03, -5.98578592e-04,\n",
            "        4.70862731e-02,  6.06073174e-02, -7.85492505e-02,  2.90030073e-02,\n",
            "       -4.49327736e-03,  2.15138899e-02,  2.97890322e-02,  5.15037235e-02,\n",
            "       -8.08602657e-02,  2.80603883e-02,  8.57274237e-02, -1.00052094e-01,\n",
            "       -3.50043521e-02,  8.48989951e-02,  3.80244810e-02,  6.84789174e-03,\n",
            "        5.92825898e-02,  3.01305139e-02,  1.64299453e-02,  2.72648036e-03,\n",
            "        1.04390744e-01, -5.96347090e-02,  5.68516223e-02,  2.74902463e-03,\n",
            "       -7.20708160e-02, -8.61840503e-02, -1.94254636e-02,  7.55049976e-02,\n",
            "        2.25872131e-02,  4.38485412e-02,  2.02990744e-02,  1.05640908e-02,\n",
            "        7.56041598e-02, -1.18648013e-01,  8.87562641e-02,  7.19954295e-02,\n",
            "       -7.73975147e-02,  1.64716464e-03,  1.27498256e-02, -2.34810783e-02,\n",
            "        8.16636607e-03,  1.60911330e-01, -1.19165139e-01,  5.92049328e-02,\n",
            "        4.98998056e-02,  5.36208262e-02, -3.63621596e-02,  1.90191695e-02,\n",
            "       -7.87895793e-02, -5.63756529e-02,  1.03098231e-02, -1.82513584e-03,\n",
            "       -1.48912470e-02,  3.80284306e-02,  2.49467371e-02, -3.72486301e-02,\n",
            "       -2.82589510e-04,  4.15089026e-02, -2.80517338e-02, -2.95348960e-02,\n",
            "        1.48658285e-01,  5.49312100e-02,  1.42154421e-02,  6.81932809e-02,\n",
            "       -3.89423478e-02,  3.98965621e-02,  1.56770921e-02, -6.92552045e-02,\n",
            "       -1.02219275e-02, -7.13882784e-02, -8.25767493e-02,  5.79893123e-02,\n",
            "       -4.13636502e-02,  2.48832600e-02, -2.57163158e-02,  6.19300205e-02,\n",
            "        2.62261288e-02, -1.90549018e-01, -2.59465868e-02,  9.42976494e-03])]\n"
          ]
        }
      ],
      "source": [
        "address, tag = train_dataset_vectorizer[0]  # Unpack the first tuple\n",
        "print(f\"The vectorized address is now a list of vectors {address}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0o_YfTO3hNT2",
        "outputId": "f89671ed-f3d3-4eca-9e36-b685c4ca439a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('10/1004  tikunijiwadi road  shubharambh  manpada  thane west    400610',\n",
              "  ['flat_apartment_number',\n",
              "   'street',\n",
              "   'street',\n",
              "   'society_name',\n",
              "   'unknown',\n",
              "   'city_town',\n",
              "   'unknown',\n",
              "   'pincode']),\n",
              " ('b-4/1  s n 7/8 tatya tope society    opp shivarkar garden  wanowrie  pune 411040  ',\n",
              "  ['flat_apartment_number',\n",
              "   'society_name',\n",
              "   'street',\n",
              "   'street',\n",
              "   'society_name',\n",
              "   'society_name',\n",
              "   'society_name',\n",
              "   'landmark',\n",
              "   'landmark',\n",
              "   'landmark',\n",
              "   'area_locality_name',\n",
              "   'city_town',\n",
              "   'pincode']),\n",
              " ('2  reshma residency  paramhans ngr  paud rd  kothrud  chinchwad  411038',\n",
              "  ['flat_apartment_number',\n",
              "   'society_name',\n",
              "   'society_name',\n",
              "   'sub_locality',\n",
              "   'sub_locality',\n",
              "   'street',\n",
              "   'street',\n",
              "   'area_locality_name',\n",
              "   'unknown',\n",
              "   'pincode']),\n",
              " ('2  riddhiraj society  nursery road  b/h yashoda heights  gohaur baugh  bilimora  gandevi  396321',\n",
              "  ['flat_apartment_number',\n",
              "   'society_name',\n",
              "   'society_name',\n",
              "   'street',\n",
              "   'street',\n",
              "   'landmark',\n",
              "   'landmark',\n",
              "   'landmark',\n",
              "   'unknown',\n",
              "   'sub_locality',\n",
              "   'area_locality_name',\n",
              "   'city_town',\n",
              "   'pincode']),\n",
              " ('a-2  madhuvan colony  thatipur  gwalior  474011',\n",
              "  ['flat_apartment_number',\n",
              "   'society_name',\n",
              "   'society_name',\n",
              "   'area_locality_name',\n",
              "   'city_town',\n",
              "   'pincode']),\n",
              " ('003 a triveni palace  ram nagar  shivmandir road  dombivli east 421201  ',\n",
              "  ['flat_apartment_number',\n",
              "   'flat_apartment_number',\n",
              "   'society_name',\n",
              "   'society_name',\n",
              "   'sub_locality',\n",
              "   'sub_locality',\n",
              "   'street',\n",
              "   'street',\n",
              "   'city_town',\n",
              "   'unknown',\n",
              "   'pincode']),\n",
              " ('h-3  shanti apartment  sector-13  rohini  delhi-110085  new delhi  110085',\n",
              "  ['flat_apartment_number',\n",
              "   'society_name',\n",
              "   'society_name',\n",
              "   'sub_locality',\n",
              "   'area_locality_name',\n",
              "   'unknown',\n",
              "   'city_town',\n",
              "   'city_town',\n",
              "   'pincode']),\n",
              " ('3  datta chowk    south kasba  varad hospital;datta solapur    413007',\n",
              "  ['flat_apartment_number',\n",
              "   'street',\n",
              "   'street',\n",
              "   'society_name',\n",
              "   'society_name',\n",
              "   'landmark',\n",
              "   'unknown',\n",
              "   'area_locality_name',\n",
              "   'pincode']),\n",
              " ('f-3  birla road    jalaram vatika  colony  akola  444001',\n",
              "  ['flat_apartment_number',\n",
              "   'street',\n",
              "   'street',\n",
              "   'society_name',\n",
              "   'society_name',\n",
              "   'unknown',\n",
              "   'city_town',\n",
              "   'pincode']),\n",
              " ('g2/3 building g2  iti road  shirine garden  near parihaar chowk    opp  aundh  pune  411007',\n",
              "  ['flat_apartment_number',\n",
              "   'flat_apartment_number',\n",
              "   'flat_apartment_number',\n",
              "   'street',\n",
              "   'street',\n",
              "   'society_name',\n",
              "   'society_name',\n",
              "   'landmark',\n",
              "   'landmark',\n",
              "   'landmark',\n",
              "   'unknown',\n",
              "   'area_locality_name',\n",
              "   'city_town',\n",
              "   'pincode'])]"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ],
      "source": [
        "train_data[:10] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZArjV29J_zq"
      },
      "outputs": [],
      "source": [
        "def pad_collate_fn(batch):\n",
        "    \"\"\"\n",
        "    The collate_fn that can add padding to the sequences so all can have\n",
        "    the same length as the longest one.\n",
        "\n",
        "    Args:\n",
        "        batch (List[List, List]): The batch data, where the first element\n",
        "        of the tuple is the word idx and the second element are the target\n",
        "        label.\n",
        "\n",
        "    Returns:\n",
        "        A tuple (x, y). The element x is a tensor of packed sequence .\n",
        "        The element y is a tensor of padded tag indices. The word vectors are\n",
        "        padded with vectors of 0s and the tag indices are padded with -100s.\n",
        "        Padding with -100 is done because of the cross-entropy loss and the\n",
        "        accuracy metric ignores the targets with values -100.\n",
        "    \"\"\"\n",
        "\n",
        "    # This gets us two lists of tensors and a list of integer.\n",
        "    # Each tensor in the first list is a sequence of word vectors.\n",
        "    # Each tensor in the second list is a sequence of tag indices.\n",
        "    # The list of integer consist of the lengths of the sequences in order.\n",
        "    sequences_vectors, sequences_labels, lengths = zip(\n",
        "        *[\n",
        "            (torch.FloatTensor(seq_vectors), torch.LongTensor(labels), len(seq_vectors))\n",
        "            for (seq_vectors, labels) in sorted(\n",
        "                batch, key=lambda x: len(x[0]), reverse=True\n",
        "            )\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # print(\"Sequences: \", sequences_vectors)\n",
        "    # print(\"Labels: \", sequences_labels)\n",
        "\n",
        "    lengths = torch.LongTensor(lengths)\n",
        "\n",
        "    padded_sequences_vectors = pad_sequence(\n",
        "        sequences_vectors, batch_first=True, padding_value=0\n",
        "    )\n",
        "    pack_padded_sequences_vectors = pack_padded_sequence(\n",
        "        padded_sequences_vectors, lengths.cpu(), batch_first=True\n",
        "    )  # We pack the padded sequence to improve the computational speed during training\n",
        "\n",
        "    padded_sequences_labels = pad_sequence(\n",
        "        sequences_labels, batch_first=True, padding_value=-100\n",
        "    )\n",
        "\n",
        "    return pack_padded_sequences_vectors, padded_sequences_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IcxcBXBzP2Un"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(\n",
        "    train_dataset_vectorizer,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    collate_fn=pad_collate_fn,\n",
        "    num_workers=2,\n",
        ")\n",
        "valid_loader = DataLoader(\n",
        "    valid_dataset_vectorizer,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=pad_collate_fn,\n",
        "    num_workers=2,\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    test_dataset_vectorizer,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=pad_collate_fn,\n",
        "    num_workers=2,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMzE_hNzofnK"
      },
      "outputs": [],
      "source": [
        "def __getitem__(self, index):\n",
        "    # get the sequence and label at the specified index\n",
        "    seq, label = self.sequences[index], self.labels[index]\n",
        "    \n",
        "    # convert the sequence to a tensor of word embeddings\n",
        "    seq_vectors = torch.stack([torch.tensor(self.word_embeddings[word]) for word in seq])\n",
        "    \n",
        "    # pad the sequence and label\n",
        "    padded_seq = pad_sequence([seq_vectors], batch_first=True)\n",
        "    padded_label = pad_sequence([torch.LongTensor(label)], batch_first=True, padding_value=-1)\n",
        "    \n",
        "    print(f\"Padded sequences size: {padded_seq.size()}\")\n",
        "    print(f\"Padded labels size: {padded_label.size()}\")\n",
        "    \n",
        "    return padded_seq[0], padded_label[0], len(seq_vectors)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-gQ83rdpSg3"
      },
      "outputs": [],
      "source": [
        "subset = train_data[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YahruqZ0pXfk",
        "outputId": "f3ee5dc4-2653-4125-dd20-507d42bb7eba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('10/1004  tikunijiwadi road  shubharambh  manpada  thane west    400610',\n",
              "  ['flat_apartment_number',\n",
              "   'street',\n",
              "   'street',\n",
              "   'society_name',\n",
              "   'unknown',\n",
              "   'city_town',\n",
              "   'unknown',\n",
              "   'pincode']),\n",
              " ('b-4/1  s n 7/8 tatya tope society    opp shivarkar garden  wanowrie  pune 411040  ',\n",
              "  ['flat_apartment_number',\n",
              "   'society_name',\n",
              "   'street',\n",
              "   'street',\n",
              "   'society_name',\n",
              "   'society_name',\n",
              "   'society_name',\n",
              "   'landmark',\n",
              "   'landmark',\n",
              "   'landmark',\n",
              "   'area_locality_name',\n",
              "   'city_town',\n",
              "   'pincode'])]"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ],
      "source": [
        "subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDo86xqHl2VC",
        "outputId": "ed09d4e9-094e-436c-9c05-9284c61a7592"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 23])\n",
            "torch.Size([64, 18])\n",
            "torch.Size([64, 18])\n",
            "torch.Size([64, 20])\n",
            "torch.Size([64, 22])\n",
            "torch.Size([64, 19])\n",
            "torch.Size([64, 17])\n",
            "torch.Size([64, 19])\n",
            "torch.Size([64, 20])\n",
            "torch.Size([64, 17])\n",
            "torch.Size([64, 19])\n",
            "torch.Size([17, 17])\n"
          ]
        }
      ],
      "source": [
        "for batch_idx, (data, target) in enumerate(train_loader):\n",
        "    # target is the name of your labels tensor\n",
        "    print(target.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWIvHQLvmGE9",
        "outputId": "385b23ab-b560-472e-8168-9e20de198f44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 22])\n",
            "torch.Size([64, 19])\n",
            "torch.Size([64, 20])\n",
            "torch.Size([64, 20])\n",
            "torch.Size([64, 23])\n",
            "torch.Size([64, 19])\n",
            "torch.Size([64, 15])\n",
            "torch.Size([64, 19])\n",
            "torch.Size([64, 17])\n",
            "torch.Size([64, 17])\n",
            "torch.Size([64, 19])\n",
            "torch.Size([17, 16])\n"
          ]
        }
      ],
      "source": [
        "for batch_idx, (data, target) in enumerate(valid_loader):\n",
        "    # target is the name of your labels tensor\n",
        "    print(target.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTjcUSK8LGaJ"
      },
      "outputs": [],
      "source": [
        "class RecurrentNet(nn.Module):\n",
        "    def __init__(self, lstm_network, fully_connected_network):\n",
        "        super().__init__()\n",
        "        self.hidden_state = None\n",
        "\n",
        "        self.lstm_network = lstm_network\n",
        "        self.fully_connected_network = fully_connected_network\n",
        "\n",
        "    def forward(self, packed_sequences_vectors):\n",
        "        \"\"\"\n",
        "        Defines the computation performed at every call.\n",
        "\n",
        "        Shapes:\n",
        "            packed_sequence_vectors: batch_size * longest_sequence_length (padding), 300\n",
        "\n",
        "        \"\"\"\n",
        "        # packed_sequences = pack_padded_sequence(inputs, seq_lengths, batch_first=True, enforce_sorted=False)\n",
        "        lstm_out, self.hidden_state = self.lstm_network(packed_sequences_vectors)\n",
        "        lstm_out, _ = pad_packed_sequence(lstm_out, batch_first=True)\n",
        "\n",
        "        tag_space = self.fully_connected_network(lstm_out)\n",
        "        return tag_space.transpose(-1, 1)  # We need to transpose since it's a sequence\n",
        "\n",
        "\n",
        "full_network = RecurrentNet(lstm_network, fully_connected_network)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuT5dCooKaqx"
      },
      "outputs": [],
      "source": [
        "# DONT RUN FOR BIDIRECTIONAL\n",
        "#  optimizer = optim.SGD(full_network.parameters(), lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnJs3elEK98n"
      },
      "outputs": [],
      "source": [
        "# DONT RUN FOR BIDIRECTIONAL\n",
        "# exp = Experiment(\n",
        "#     \"./\",\n",
        "#     full_network,\n",
        "#     device=device,\n",
        "#     optimizer=optimizer,\n",
        "#     loss_function=cross_entropy,\n",
        "#     batch_metrics=[\"acc\"],\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idkz3ak6D-pZ"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# torch.backends.cudnn.benchmark = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVl0sDpcD1a3"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-f_DSAOLKlq"
      },
      "outputs": [],
      "source": [
        "# exp.train(train_loader,\"\" valid_generator=valid_loader, epochs=epoch_number)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spL4r_I2kVA0"
      },
      "outputs": [],
      "source": [
        "dimension = 300\n",
        "num_layer = 2\n",
        "bidirectional = True\n",
        "\n",
        "lstm_network = nn.LSTM(\n",
        "    input_size=dimension,\n",
        "    hidden_size=dimension,\n",
        "    num_layers=num_layer,\n",
        "    bidirectional=bidirectional,\n",
        "    batch_first=True,\n",
        ")\n",
        "\n",
        "input_dim = dimension * 2  # since bidirectional\n",
        "\n",
        "fully_connected_network = nn.Linear(input_dim, tag_dimension)\n",
        "\n",
        "full_network_bi_lstm = RecurrentNet(lstm_network, fully_connected_network)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XPWjUvdl2Us",
        "outputId": "8801e8be-c2b1-49ee-9145-9ac252476553"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parameter containing:\n",
            "tensor([[-0.0281,  0.0339,  0.0509,  ..., -0.0276, -0.0470,  0.0484],\n",
            "        [-0.0231,  0.0153, -0.0200,  ..., -0.0223, -0.0112, -0.0491],\n",
            "        [-0.0367, -0.0094,  0.0438,  ...,  0.0002,  0.0116,  0.0200],\n",
            "        ...,\n",
            "        [-0.0541,  0.0203, -0.0274,  ...,  0.0519,  0.0299,  0.0427],\n",
            "        [ 0.0464,  0.0255, -0.0432,  ..., -0.0105, -0.0439,  0.0035],\n",
            "        [ 0.0230, -0.0242,  0.0401,  ..., -0.0320,  0.0132,  0.0009]],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([[-0.0054, -0.0010, -0.0257,  ..., -0.0513,  0.0387, -0.0502],\n",
            "        [-0.0502,  0.0305,  0.0139,  ..., -0.0380, -0.0515, -0.0116],\n",
            "        [ 0.0265, -0.0244,  0.0560,  ...,  0.0133, -0.0458,  0.0145],\n",
            "        ...,\n",
            "        [ 0.0076,  0.0117, -0.0122,  ..., -0.0032, -0.0343, -0.0574],\n",
            "        [ 0.0299, -0.0117,  0.0512,  ...,  0.0185,  0.0126,  0.0026],\n",
            "        [ 0.0464, -0.0058, -0.0543,  ...,  0.0414,  0.0348,  0.0102]],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([-0.0166, -0.0528,  0.0184,  ..., -0.0425,  0.0306,  0.0448],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([ 0.0023, -0.0011, -0.0250,  ...,  0.0089, -0.0038,  0.0031],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([[ 0.0031,  0.0472,  0.0493,  ...,  0.0573,  0.0041, -0.0073],\n",
            "        [-0.0076, -0.0511, -0.0440,  ..., -0.0127,  0.0207, -0.0290],\n",
            "        [ 0.0189,  0.0390,  0.0440,  ...,  0.0050,  0.0193,  0.0312],\n",
            "        ...,\n",
            "        [-0.0166, -0.0129,  0.0206,  ...,  0.0423, -0.0138,  0.0499],\n",
            "        [ 0.0051, -0.0485,  0.0154,  ...,  0.0102, -0.0056, -0.0379],\n",
            "        [-0.0078, -0.0567,  0.0522,  ...,  0.0486, -0.0526,  0.0353]],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([[-0.0132,  0.0386,  0.0439,  ..., -0.0423,  0.0055, -0.0376],\n",
            "        [-0.0213,  0.0134,  0.0206,  ...,  0.0107,  0.0370, -0.0074],\n",
            "        [-0.0109, -0.0124, -0.0443,  ..., -0.0545, -0.0228,  0.0468],\n",
            "        ...,\n",
            "        [ 0.0196, -0.0498,  0.0567,  ..., -0.0471, -0.0468, -0.0074],\n",
            "        [ 0.0337,  0.0309,  0.0367,  ..., -0.0015,  0.0327, -0.0333],\n",
            "        [ 0.0103, -0.0123,  0.0211,  ...,  0.0049,  0.0387,  0.0524]],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([-0.0158, -0.0182,  0.0155,  ..., -0.0378, -0.0093,  0.0520],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([-0.0124,  0.0573, -0.0253,  ..., -0.0151, -0.0416, -0.0482],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([[ 0.0003,  0.0122,  0.0561,  ...,  0.0467,  0.0264, -0.0400],\n",
            "        [ 0.0186, -0.0469, -0.0418,  ...,  0.0335, -0.0051, -0.0102],\n",
            "        [-0.0209, -0.0492,  0.0125,  ...,  0.0185, -0.0363, -0.0092],\n",
            "        ...,\n",
            "        [ 0.0452,  0.0500, -0.0138,  ..., -0.0004, -0.0164,  0.0184],\n",
            "        [ 0.0342,  0.0167, -0.0374,  ..., -0.0294, -0.0131,  0.0285],\n",
            "        [-0.0257,  0.0026, -0.0297,  ...,  0.0505, -0.0194,  0.0457]],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([[-0.0229,  0.0505,  0.0444,  ...,  0.0394, -0.0205,  0.0301],\n",
            "        [ 0.0179,  0.0152,  0.0255,  ..., -0.0358,  0.0517,  0.0487],\n",
            "        [-0.0257, -0.0328,  0.0022,  ...,  0.0004,  0.0292, -0.0414],\n",
            "        ...,\n",
            "        [ 0.0264, -0.0337,  0.0205,  ...,  0.0158,  0.0072, -0.0030],\n",
            "        [-0.0493, -0.0453, -0.0102,  ...,  0.0382, -0.0515,  0.0478],\n",
            "        [ 0.0232, -0.0470, -0.0562,  ..., -0.0003, -0.0068,  0.0505]],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([ 0.0015,  0.0433, -0.0553,  ..., -0.0457,  0.0377,  0.0501],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([-0.0452,  0.0431,  0.0191,  ...,  0.0284, -0.0129,  0.0573],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([[ 0.0007, -0.0344, -0.0314,  ...,  0.0278, -0.0509,  0.0234],\n",
            "        [-0.0269, -0.0108,  0.0310,  ...,  0.0121,  0.0068, -0.0379],\n",
            "        [ 0.0142,  0.0341, -0.0256,  ...,  0.0347, -0.0089,  0.0248],\n",
            "        ...,\n",
            "        [-0.0253,  0.0090, -0.0407,  ...,  0.0505,  0.0521,  0.0250],\n",
            "        [ 0.0017,  0.0532,  0.0020,  ..., -0.0553, -0.0269, -0.0139],\n",
            "        [-0.0012, -0.0223,  0.0087,  ...,  0.0501,  0.0342, -0.0524]],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([[-0.0488, -0.0459,  0.0380,  ..., -0.0220,  0.0559,  0.0361],\n",
            "        [ 0.0312, -0.0387,  0.0223,  ..., -0.0199,  0.0445, -0.0284],\n",
            "        [-0.0395, -0.0480, -0.0474,  ..., -0.0160,  0.0207,  0.0039],\n",
            "        ...,\n",
            "        [-0.0520, -0.0048,  0.0223,  ...,  0.0273,  0.0442,  0.0137],\n",
            "        [ 0.0304,  0.0164, -0.0271,  ...,  0.0170,  0.0414,  0.0159],\n",
            "        [ 0.0047, -0.0024, -0.0139,  ...,  0.0572, -0.0337,  0.0411]],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([ 0.0418, -0.0140,  0.0301,  ...,  0.0295,  0.0546,  0.0429],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([-0.0177, -0.0248, -0.0089,  ...,  0.0012,  0.0255, -0.0101],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([[-0.0328,  0.0297, -0.0055,  ..., -0.0204,  0.0341,  0.0110],\n",
            "        [ 0.0107, -0.0037,  0.0245,  ..., -0.0231, -0.0374,  0.0406],\n",
            "        [ 0.0261,  0.0275,  0.0087,  ...,  0.0136, -0.0351, -0.0314],\n",
            "        ...,\n",
            "        [ 0.0061,  0.0341, -0.0261,  ...,  0.0300, -0.0124, -0.0401],\n",
            "        [-0.0309,  0.0392, -0.0076,  ...,  0.0162,  0.0029,  0.0394],\n",
            "        [ 0.0104, -0.0280, -0.0177,  ...,  0.0054, -0.0354,  0.0139]],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([ 0.0152,  0.0286,  0.0189,  0.0041, -0.0187, -0.0264, -0.0008,  0.0110,\n",
            "         0.0222,  0.0126], requires_grad=True)]\n"
          ]
        }
      ],
      "source": [
        "print(list(full_network_bi_lstm.parameters()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPkznpzdl6lZ"
      },
      "outputs": [],
      "source": [
        "# optimizer.add_parameters(full_network_bi_lstm.parameters())\n",
        "optimizer = optim.SGD(full_network_bi_lstm.parameters(), lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gs_8aeuBkaEV",
        "outputId": "a2213456-c3bd-40a4-b5fa-817bca6f66c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading weights from ./checkpoint.ckpt and starting at epoch 11.\n",
            "Loading optimizer state from ./checkpoint.optim and starting at epoch 11.\n",
            "Loading random states from ./checkpoint.randomstate and starting at epoch 11.\n",
            "Restoring data from ./checkpoint_epoch_10.ckpt\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ],
      "source": [
        "exp_bi_lstm = Experiment(\n",
        "    \"./\",\n",
        "    full_network_bi_lstm,\n",
        "    device=device,\n",
        "    optimizer=optimizer,\n",
        "    loss_function=cross_entropy,\n",
        "    batch_metrics=[\"acc\"],\n",
        ")\n",
        "exp_bi_lstm.train(train_loader, valid_generator=valid_loader, epochs=epoch_number)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSGR9WaNe2Uf"
      },
      "outputs": [],
      "source": [
        "# Assuming the model is named \"full_network_bi_lstm\"\n",
        "torch.save(full_network_bi_lstm.state_dict(), 'model.pth')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSyBkZD6ow6l",
        "outputId": "55100b68-3e85-42ac-f5bd-582944f82e57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found best checkpoint at epoch: 10\n",
            "lr: 0.1, loss: 2.11886, acc: 18.0592, val_loss: 2.11161, val_acc: 18.0724\n",
            "Loading checkpoint ./checkpoint_epoch_10.ckpt\n",
            "Running test\n",
            "\u001b[35mTest steps: \u001b[36m12 \u001b[32m20.11s \u001b[35mtest_loss:\u001b[94m 2.111607\u001b[35m test_acc:\u001b[94m 18.072392\u001b[0m                                               \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'time': 20.114282491999802,\n",
              " 'test_loss': 2.111607314809516,\n",
              " 'test_acc': 18.07239246236137}"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ],
      "source": [
        "# exp.test(test_loader)\n",
        "exp_bi_lstm.test(test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_network_bi_lstm.to(device)\n",
        "full_network_bi_lstm.eval()\n",
        "res = []\n",
        "tags_set = {\n",
        "    'flat_apartment_number' : 0,\n",
        "    'society_name' : 1,\n",
        "    # 'building no': 2,\n",
        "    'street': 2,\n",
        "    'landmark': 3,\n",
        "    'sub_locality' : 4,\n",
        "    'area_locality_name' : 5,\n",
        "    'city_town': 6,\n",
        "    'pincode': 7,\n",
        "    'unknown': 8\n",
        "        }\n",
        "test_sent ='b4 purandhar housing society uruli kanchan pune haveli 412202'\n",
        "test_sent_vec = embedding_vectorizer(test_sent)\n",
        "test_sent_tensor = torch.tensor([test_sent_vec], dtype=torch.float32).to(device)\n",
        "test_sent_tensor_len = torch.tensor([test_sent_tensor.size()[1]], dtype=torch.long).to(device)\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    # Convert the input tensor to a packed sequence\n",
        "    test_sent_res = pack_padded_sequence(test_sent_tensor, test_sent_tensor_len.to('cpu'), batch_first=True, enforce_sorted=False)\n",
        "    # packed_sequences = nn.utils.rnn.pack_padded_sequence(padded_tensor, valid_frames.to('cpu'), batch_first=True, enforce_sorted=True) \n",
        "\n",
        "    # test_sent_res = full_network_bi_lstm(test_sent_res, test_sent_tensor_len)\n",
        "    test_sent_res = full_network_bi_lstm(test_sent_res)\n",
        "\n",
        "\n",
        "    out = test_sent_res.cpu()[0]\n",
        "    out = torch.argmax(out,dim=1)\n",
        "    \n",
        "    \n",
        "    for c in out:\n",
        "        res.append(list(tags_set.keys())[list(tags_set.values()).index(c.item())])\n",
        "\n",
        "    print(f'Predicted: {res}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMeaiSUVChB8",
        "outputId": "c5aef638-7d00-48de-f3e8-e96f7519ab9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: ['flat_apartment_number', 'landmark', 'street', 'sub_locality', 'unknown', 'unknown', 'unknown', 'unknown', 'city_town', 'unknown']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "# from my_model import MyModel\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Load the saved model\n",
        "model = torch.load('/content/complete_model.pt', map_location=device)\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOay9dynTtIQ",
        "outputId": "57b57e8e-599d-4795-d678-6dda9e3cabde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RecurrentNet(\n",
              "  (lstm_network): LSTM(300, 300, num_layers=2, batch_first=True, bidirectional=True)\n",
              "  (fully_connected_network): Linear(in_features=600, out_features=9, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def unpack_packed_sequence(packed_sequence):\n",
        "    return packed_sequence.data"
      ],
      "metadata": {
        "id": "o3MtIu79Qjfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "model.to(device)\n",
        "model.eval()\n",
        "res = []\n",
        "tags_set = {\n",
        "    'flat_apartment_number' : 0,\n",
        "    'society_name' : 1,\n",
        "    # 'building no': 2,\n",
        "    'street': 2,\n",
        "    'landmark': 3,\n",
        "    'sub_locality' : 4,\n",
        "    'area_locality_name' : 5,\n",
        "    'city_town': 6,\n",
        "    'pincode': 7,\n",
        "    'unknown': 8\n",
        "        }\n",
        "test_sent ='G-909 Rohan Garima SB Road Shivajinagar Pune 411016'\n",
        "test_sent_vec = embedding_vectorizer(test_sent)\n",
        "test_sent_tensor = torch.tensor([test_sent_vec], dtype=torch.float32).to(device)\n",
        "test_sent_tensor_len = torch.tensor([test_sent_tensor.size()[1]], dtype=torch.long).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    # Convert the input tensor to a packed sequence\n",
        "    test_sent_res = pack_padded_sequence(test_sent_tensor, test_sent_tensor_len.to('cpu'), batch_first=True, enforce_sorted=False)\n",
        "\n",
        "    # Pass the packed sequence through the model\n",
        "    test_sent_res = model(test_sent_res)\n",
        "\n",
        "    # Unpack the packed sequence to get the output tensor\n",
        "    # test_sent_res, _ = pad_packed_sequence(test_sent_res, batch_first=True)\n",
        "    test_sent_res = unpack_packed_sequence(test_sent_res)\n",
        "\n",
        "    # Get the original lengths of the input sequences\n",
        "    lengths = test_sent_tensor_len.cpu().numpy()\n",
        "\n",
        "    # Iterate over the batch and exclude padded tokens\n",
        "    for i in range(test_sent_res.size(0)):\n",
        "        sequence = test_sent_res[i, :lengths[i]]\n",
        "        predicted_tags = torch.argmax(sequence, dim=1)\n",
        "\n",
        "        # Convert the predicted indices to corresponding tags\n",
        "        res = [list(tags_set.keys())[list(tags_set.values()).index(c.item())] for c in predicted_tags]\n",
        "\n",
        "        print(f'Predicted: {res}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSczqxNRNt4Z",
        "outputId": "5fdd0fd5-4576-41d5-905d-9ba90ea91c8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: ['flat_apartment_number', 'society_name', 'sub_locality', 'landmark', 'sub_locality', 'sub_locality', 'city_town', 'pincode']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BSYb6iSbT6rB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}